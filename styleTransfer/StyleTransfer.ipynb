{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "\n",
    "**Mark Wilber**\n",
    "\n",
    "Uses style transfer technique to synthesize paintings in the style of Bonnie Wilber from photographs\n",
    "\n",
    "Borrows heavily from Walid Ahmad's [Making AI Art with Style Transfer using Keras](https://medium.com/mlreview/making-ai-art-with-style-transfer-using-keras-8bb5fa44b216)\n",
    "\n",
    "<font color='darkgreen'>**As thise notebook is lengthy, readers will find it much easier to navigate with [Jupyter Nbextensions](https://github.com/ipython-contrib/jupyter_contrib_nbextensions) installed, and Table of Contents (2) selected:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "**Next two lines are useful in the event of external code changes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:45:19.108984Z",
     "start_time": "2020-04-22T05:45:19.095512Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imports\n",
    "\n",
    "**Next two lines are for pretty output for all prints in a Pandas cell, not just the last.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:45:19.454868Z",
     "start_time": "2020-04-22T05:45:19.445397Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DataSci` contains generally helpful data science stuff, while `plotHelpers` includes plot functions specifically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:45:19.713081Z",
     "start_time": "2020-04-22T05:45:19.704073Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/wilber/work/Mlib')\n",
    "# from utility import DataSci as util\n",
    "# import plotHelpers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:38.877958Z",
     "start_time": "2020-04-22T05:52:38.807450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 22 05:52:38 2020\n",
      "Python version:  (3, 6, 9, 'final', 0)\n",
      "Un-versioned imports:\n",
      "\n",
      "sys, platform, os, os.path, shutil, glob, random, collections, gc, pprint, pickle, timeitWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "\n",
      "\n",
      "dateutil: 2.8.1\tkeras: None\tmatplotlib: 3.1.3\tnumpy: 1.18.1\tPIL: 5.1.0\tscipy: 1.4.1\ttensorflow: 2.1.0\t\n",
      "\n",
      "Δt:  0.0s.\n"
     ]
    }
   ],
   "source": [
    "from time import time, asctime, gmtime\n",
    "print(asctime(gmtime()))\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# from platform import node\n",
    "import os\n",
    "from os.path import exists\n",
    "# import shutil\n",
    "# from glob import glob\n",
    "# from random import random\n",
    "# from collections import Counter, OrderedDict\n",
    "# import gc\t\t# garbage collection module\n",
    "# import pprint\n",
    "# import pickle\n",
    "# import timeit\n",
    "\n",
    "print(\"Python version: \", sys.version_info[:])\n",
    "print(\"Un-versioned imports:\\n\")\n",
    "if 'sys' in sys.modules:\n",
    "    print('sys', end=\"\")\n",
    "if 'utility' in sys.modules:\n",
    "    print(', utility', end=\"\")\n",
    "if 'plotHelpers' in sys.modules:\n",
    "    print(', plotHelpers', end=\"\")\n",
    "if 'platform' in sys.modules:\n",
    "    print(', platform', end=\"\")\n",
    "if 'os' in sys.modules:\n",
    "    print(', os', end=\"\")\n",
    "if 'os.path' in sys.modules:\n",
    "    print(', os.path', end=\"\")\n",
    "if 'shutil' in sys.modules:\n",
    "    print(', shutil', end=\"\")\n",
    "if 'glob' in sys.modules:\n",
    "    print(', glob', end=\"\")\n",
    "if 'random' in sys.modules:\n",
    "    print(', random', end=\"\")\n",
    "if 'collections' in sys.modules:\n",
    "    print(', collections', end=\"\")\n",
    "if 'gc' in sys.modules:\n",
    "    print(', gc', end=\"\")\n",
    "if 'pprint' in sys.modules:\n",
    "    print(', pprint', end=\"\")\n",
    "if 'pickle' in sys.modules:\n",
    "    print(', pickle', end=\"\")\n",
    "if 'timeit' in sys.modules:\n",
    "    print(', timeit', end=\"\")\n",
    "\n",
    "import dateutil as du\n",
    "# from dateutil.parser import parse\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import pyreadr\n",
    "\n",
    "from scipy import __version__ as scVersion\n",
    "# import scipy.sparse as sp\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "kerVersion = None\n",
    "# from keras import __version__ as kerVersion\n",
    "# from keras import backend as K\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications import VGG16\n",
    "# from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Input\n",
    "\n",
    "tfVersion = None\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow import __version__ as tfVersion\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from PIL import Image, __version__ as pilVersion\n",
    "\n",
    "# from sklearn import __version__ as skVersion\n",
    "# from sklearn.feature_extraction import text\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_selection import chi2\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.svm import LinearSVC, SVC\n",
    "# from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# from joblib import __version__ as jlVersion\n",
    "# from joblib import dump, load\n",
    "\n",
    "# import seaborn as sns\n",
    "# import colorcet as cc\n",
    "from matplotlib import __version__ as mpVersion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\")\n",
    "if 'colorcet' in sys.modules:\n",
    "    print(\"colorcet: {0}\".format(cc.__version__), end=\"\\t\")\n",
    "if 'dateutil' in sys.modules:\n",
    "    print(\"dateutil: {0}\".format(du.__version__), end=\"\\t\")\n",
    "if 'joblib' in sys.modules:\n",
    "    print(\"joblib: {0}\".format(jlVersion), end=\"\\t\")\n",
    "if 'keras' in sys.modules:\n",
    "    print(\"keras: {0}\".format(kerVersion), end=\"\\t\")\n",
    "if 'matplotlib' in sys.modules:\n",
    "    print(\"matplotlib: {0}\".format(mpVersion), end=\"\\t\")\n",
    "if 'numpy' in sys.modules:\n",
    "    print(\"numpy: {0}\".format(np.__version__), end=\"\\t\")\n",
    "# if 'pandas' in sys.modules:\n",
    "#     print(\"pandas: {0}\".format(pd.__version__), end=\"\\t\")\n",
    "if 'PIL' in sys.modules:\n",
    "    print(\"PIL: {0}\".format(pilVersion), end=\"\\t\")\n",
    "if 'pyreader' in sys.modules:\n",
    "    print(\"pyreader: {0}\".format(pyreader.__version__), end=\"\\t\")\n",
    "if 'seaborn' in sys.modules:\n",
    "    print(\"seaborn: {0}\".format(sns.__version__), end=\"\\t\")\n",
    "if 'scipy' in sys.modules:\n",
    "    print(\"scipy: {0}\".format(scVersion), end=\"\\t\")\n",
    "if 'sklearn' in sys.modules:\n",
    "    print(\"sklearn: {0}\".format(skVersion), end=\"\\t\")\n",
    "if 'tensorflow' in sys.modules:\n",
    "    print(\"tensorflow: {0}\".format(tf.__version__), end=\"\\t\")\n",
    "# if '' in sys.modules:\n",
    "#     print(\": {0}\".format(.__version__), end=\"\\t\")\n",
    "Δt = time() - t0\n",
    "print(f\"\\n\\nΔt: {Δt: 4.1f}s.\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that TensorFlow is finding the GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:43.126726Z",
     "start_time": "2020-04-22T05:52:42.893036Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.1.0\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9288615357406322693\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18197068225862453762\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6721673413514176917\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7722459050616566981\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow: {0}\".format(tf.__version__), end=\"\\n\\n\")\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### `getFeatureRepresentations()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:46.823674Z",
     "start_time": "2020-04-22T05:52:46.792518Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFeatureRepresentations(x, layer_names, model):\n",
    "    \"\"\"\n",
    "    Get feature representations of input x for one or more layers in a given model.\n",
    "    \"\"\"\n",
    "    featMatrices = []\n",
    "    for ln in layer_names:\n",
    "        selectedLayer = model.get_layer(ln)\n",
    "        featRaw = selectedLayer.output\n",
    "        featRawShape = K.shape(featRaw).eval(session=tf_session)\n",
    "        N_l = featRawShape[-1]\n",
    "        M_l = featRawShape[1]*featRawShape[2]\n",
    "        featMatrix = K.reshape(featRaw, (M_l, N_l))\n",
    "        featMatrix = K.transpose(featMatrix)\n",
    "        featMatrices.append(featMatrix)\n",
    "    return featMatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getContentLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:48.152525Z",
     "start_time": "2020-04-22T05:52:48.123600Z"
    }
   },
   "outputs": [],
   "source": [
    "def getContentLoss(F, P):\n",
    "    cLoss = 0.5*K.sum(K.square(F - P))\n",
    "    return cLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getGramMatrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:49.857725Z",
     "start_time": "2020-04-22T05:52:49.829318Z"
    }
   },
   "outputs": [],
   "source": [
    "def getGramMatrix(F):\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getStyleLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:51.234580Z",
     "start_time": "2020-04-22T05:52:51.202671Z"
    }
   },
   "outputs": [],
   "source": [
    "def getStyleLoss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_l = K.int_shape(G)[1]\n",
    "        N_l = K.int_shape(G)[0]\n",
    "        G_gram = getGramMatrix(G)\n",
    "        A_gram = getGramMatrix(A)\n",
    "        sLoss+= w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_l**2 * M_l**2)\n",
    "    return sLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getTotalLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:52.192346Z",
     "start_time": "2020-04-22T05:52:52.162657Z"
    }
   },
   "outputs": [],
   "source": [
    "# def getTotalLoss(gImPlaceholder, alpha=1.0, beta=10000.0):\n",
    "def getTotalLoss(gImPlaceholder, alpha=1.0, beta=1000.0):\n",
    "    F = getFeatureRepresentations(gImPlaceholder, layer_names=[contentLayerName], model=generatedModel)[0]\n",
    "    Gs = getFeatureRepresentations(gImPlaceholder, layer_names=styleLayerNames, model=generatedModel)\n",
    "    contentLoss = getContentLoss(F, P)\n",
    "    styleLoss = getStyleLoss(ws, Gs, As)\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `calculateLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:53.457057Z",
     "start_time": "2020-04-22T05:52:53.428380Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculateLoss(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate total loss using K.function\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetWidth, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    loss_fcn = K.function([generatedModel.input], [getTotalLoss(generatedModel.input)])\n",
    "    return loss_fcn([gImArr])[0].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getGrad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:54.962680Z",
     "start_time": "2020-04-22T05:52:54.932022Z"
    }
   },
   "outputs": [],
   "source": [
    "def getGrad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    grad_fcn = K.function([generatedModel.input], \n",
    "                          K.gradients(getTotalLoss(generatedModel.input), [generatedModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `postProcessArray()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:56.346807Z",
     "start_time": "2020-04-22T05:52:56.315597Z"
    }
   },
   "outputs": [],
   "source": [
    "def postProcessArray(x):\n",
    "    # Zero-center by mean pixel\n",
    "    if x.shape != (targetWidth, targetHeight, 3):\n",
    "        x = x.reshape((targetWidth, targetHeight, 3))\n",
    "    x[..., 0] += 103.939\n",
    "    x[..., 1] += 116.779\n",
    "    x[..., 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[..., ::-1]\n",
    "    x = np.clip(x, 0, 255)\n",
    "    x = x.astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `reprocessArray()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:57.265898Z",
     "start_time": "2020-04-22T05:52:57.236940Z"
    }
   },
   "outputs": [],
   "source": [
    "def reprocessArray(x):\n",
    "    x = np.expand_dims(x.astype('float64'), axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `saveOriginalSize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:52:58.552358Z",
     "start_time": "2020-04-22T05:52:58.523541Z"
    }
   },
   "outputs": [],
   "source": [
    "def saveOriginalSize(x, targetSize):\n",
    "    xIm = Image.fromarray(x)\n",
    "    xIm = xIm.resize(targetSize)\n",
    "    xIm.save(targetImagePath)\n",
    "    return xIm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "\n",
    "### Content image (a photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:53:09.975895Z",
     "start_time": "2020-04-22T05:53:09.919978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "targetWidth = 512\n",
    "targetHeight = 512\n",
    "targetSize = (targetHeight, targetWidth)\n",
    "\n",
    "contentImagePath = './images/PortraitOfManHuggingHappyWomanUnderUmbrella512x512.png'\n",
    "\n",
    "contentImageOrig = Image.open(contentImagePath)\n",
    "contentImageSizeOrig = contentImageOrig.size\n",
    "contentImage = load_img(path=contentImagePath, target_size=targetSize)\n",
    "contentImageArr = img_to_array(contentImage)\n",
    "contentImageArr = K.variable(preprocess_input(np.expand_dims(contentImageArr, axis=0)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style image (Bonnie Wilber painting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:53:26.781479Z",
     "start_time": "2020-04-22T05:53:26.738671Z"
    }
   },
   "outputs": [],
   "source": [
    "styleImagePath = './images/1024pxRenoirPierre-AugusteTheTwoSistersOnTheTerrace512x512.png'\n",
    "\n",
    "styleImage = load_img(path=styleImagePath, target_size=targetSize)\n",
    "styleImageArr = img_to_array(styleImage)\n",
    "styleImageArr = K.variable(preprocess_input(np.expand_dims(styleImageArr, axis=0)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the image\n",
    "\n",
    "\n",
    "### Create session, instances of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:53:35.016618Z",
     "start_time": "2020-04-22T05:53:34.977109Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.backend' has no attribute 'get_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cf3da3d2d47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontentModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontentImageArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstyleModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyleImageArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.backend' has no attribute 'get_session'"
     ]
    }
   ],
   "source": [
    "tf_session = K.get_session()\n",
    "contentModel = VGG16(include_top=False, weights='imagenet', input_tensor=contentImageArr)\n",
    "styleModel = VGG16(include_top=False, weights='imagenet', input_tensor=styleImageArr)\n",
    "# generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify mutable layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T18:56:13.017132Z",
     "start_time": "2020-04-21T18:56:12.750166Z"
    }
   },
   "outputs": [],
   "source": [
    "contentLayerName = 'block4_conv2'\n",
    "styleLayerNames = [\n",
    "                   'block1_conv1',\n",
    "                   'block2_conv1',\n",
    "                   'block3_conv1',\n",
    "                   'block4_conv1',\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T18:56:20.345115Z",
     "start_time": "2020-04-21T18:56:19.783841Z"
    }
   },
   "outputs": [],
   "source": [
    "P = getFeatureRepresentations(x=contentImageArr, layer_names=[contentLayerName], model=contentModel)[0]\n",
    "As = getFeatureRepresentations(x=styleImageArr, layer_names=styleLayerNames, model=styleModel)\n",
    "ws = np.ones(len(styleLayerNames))/float(len(styleLayerNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the target image\n",
    "\n",
    "#### Iteration 0000-0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set random seeds to enforce consistent results\n",
    "\n",
    "This is described in more detail in Jason Brownlee's [How to Get Reproducible Results with Keras](https://machinelearningmastery.com/reproducible-results-neural-networks-keras/)\n",
    "\n",
    "**Note: this will not necessarily work when running on GPUs.**\n",
    "\n",
    "2 Steps:\n",
    "1. Set `numpy`'s random number generator seed, since Keras itself relies on this\n",
    "1. Set TensorFlow's random number generator seed, as this is invoked by TF's random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0001.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 1\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0001-0006\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0006.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 6\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0007-0013\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0013.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 13\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0014-0025\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0025.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 25\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0026-0050\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0050.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 50\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0051-0100\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0100.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 100\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0101-0150\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0150.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 150\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0151-0210\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0210.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 210\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0211-0290\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0290.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 290\n",
    "\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0351-0400\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0400.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 400\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0501-0550\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0550.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 550\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0551-0750\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at0750.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 750\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations 0751-1030\n",
    "\n",
    "##### Set random seeds to enforce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "t0 = time()\n",
    "targetImagePath = f\"./target{targetWidth}x{targetHeight}at1030.jpg\"\n",
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)\n",
    "\n",
    "iterations = 1030\n",
    "xVal = targetImage0.flatten()\n",
    "xopt, fVal, info = fmin_l_bfgs_b(calculateLoss, xVal, fprime=getGrad,\n",
    "                                 maxiter=iterations, disp=True)\n",
    "Δt = time() - t0\n",
    "hrs = int(Δt//3600)\n",
    "mins = int(int((Δt - 3600.0*hrs)//60))\n",
    "secs = Δt % 60.0\n",
    "print(f\"Δt: {hrs}h, {mins:2d}m, {secs:4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOut = postProcessArray(xopt)\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig)\n",
    "print('Image saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "613px",
    "left": "10px",
    "top": "150px",
    "width": "203.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
