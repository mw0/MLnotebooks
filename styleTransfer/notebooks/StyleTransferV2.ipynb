{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "\n",
    "**Mark Wilber**\n",
    "\n",
    "Uses style transfer technique to synthesize paintings in the style of Bonnie Wilber from photographs\n",
    "\n",
    "Borrows heavily from Walid Ahmad's [Making AI Art with Style Transfer using Keras](https://medium.com/mlreview/making-ai-art-with-style-transfer-using-keras-8bb5fa44b216)\n",
    "\n",
    "<font color='darkgreen'>**As thise notebook is lengthy, readers will find it much easier to navigate with [Jupyter Nbextensions](https://github.com/ipython-contrib/jupyter_contrib_nbextensions) installed, and Table of Contents (2) selected:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "**Next two lines are useful in the event of external code changes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imports\n",
    "\n",
    "**Next two lines are for pretty output for all prints in a Pandas cell, not just the last.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DataSci` contains generally helpful data science stuff, while `plotHelpers` includes plot functions specifically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/wilber/work/Mlib')\n",
    "# from utility import DataSci as util\n",
    "# import plotHelpers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, asctime, gmtime, localtime\n",
    "print(asctime(gmtime()))\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# from platform import node\n",
    "import os\n",
    "from os.path import exists\n",
    "# import shutil\n",
    "# from glob import glob\n",
    "# from random import random\n",
    "# from collections import Counter, OrderedDict\n",
    "# import gc\t\t# garbage collection module\n",
    "# import pprint\n",
    "# import pickle\n",
    "# import timeit\n",
    "\n",
    "print(\"Python version: \", sys.version_info[:])\n",
    "print(\"Un-versioned imports:\\n\")\n",
    "if 'sys' in sys.modules:\n",
    "    print('sys', end=\"\")\n",
    "if 'utility' in sys.modules:\n",
    "    print(', utility', end=\"\")\n",
    "if 'plotHelpers' in sys.modules:\n",
    "    print(', plotHelpers', end=\"\")\n",
    "if 'platform' in sys.modules:\n",
    "    print(', platform', end=\"\")\n",
    "if 'os' in sys.modules:\n",
    "    print(', os', end=\"\")\n",
    "if 'os.path' in sys.modules:\n",
    "    print(', os.path', end=\"\")\n",
    "if 'shutil' in sys.modules:\n",
    "    print(', shutil', end=\"\")\n",
    "if 'glob' in sys.modules:\n",
    "    print(', glob', end=\"\")\n",
    "if 'random' in sys.modules:\n",
    "    print(', random', end=\"\")\n",
    "if 'collections' in sys.modules:\n",
    "    print(', collections', end=\"\")\n",
    "if 'gc' in sys.modules:\n",
    "    print(', gc', end=\"\")\n",
    "if 'pprint' in sys.modules:\n",
    "    print(', pprint', end=\"\")\n",
    "if 'pickle' in sys.modules:\n",
    "    print(', pickle', end=\"\")\n",
    "if 'timeit' in sys.modules:\n",
    "    print(', timeit', end=\"\")\n",
    "\n",
    "import dateutil as du\n",
    "# from dateutil.parser import parse\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import pyreadr\n",
    "\n",
    "from scipy import __version__ as scVersion\n",
    "# import scipy.sparse as sp\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K, __version__ as kerVersion\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "\n",
    "from PIL import Image, __version__ as pilVersion\n",
    "\n",
    "# from sklearn import __version__ as skVersion\n",
    "# from sklearn.feature_extraction import text\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_selection import chi2\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.svm import LinearSVC, SVC\n",
    "# from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# from joblib import __version__ as jlVersion\n",
    "# from joblib import dump, load\n",
    "\n",
    "# import seaborn as sns\n",
    "# import colorcet as cc\n",
    "from matplotlib import __version__ as mpVersion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\")\n",
    "if 'dateutil' in sys.modules:\n",
    "    print(\"dateutil: {0}\".format(du.__version__), end=\"\\t\")\n",
    "if 'numpy' in sys.modules:\n",
    "    print(\"numpy: {0}\".format(np.__version__), end=\"\\t\")\n",
    "# if 'pandas' in sys.modules:\n",
    "#     print(\"pandas: {0}\".format(pd.__version__), end=\"\\t\")\n",
    "if 'pyreader' in sys.modules:\n",
    "    print(\"pyreader: {0}\".format(pyreader.__version__), end=\"\\t\")\n",
    "if 'scipy' in sys.modules:\n",
    "    print(\"scipy: {0}\".format(scVersion), end=\"\\t\")\n",
    "if 'tensorflow' in sys.modules:\n",
    "    print(\"tensorflow: {0}\".format(tf.__version__), end=\"\\t\")\n",
    "if 'keras' in sys.modules:\n",
    "    print(\"keras: {0}\".format(kerVersion), end=\"\\t\")\n",
    "if 'PIL' in sys.modules:\n",
    "    print(\"PIL: {0}\".format(pilVersion), end=\"\\t\")\n",
    "if 'sklearn' in sys.modules:\n",
    "    print(\"sklearn: {0}\".format(skVersion), end=\"\\t\")\n",
    "if 'joblib' in sys.modules:\n",
    "    print(\"joblib: {0}\".format(jlVersion), end=\"\\t\")\n",
    "if 'seaborn' in sys.modules:\n",
    "    print(\"seaborn: {0}\".format(sns.__version__), end=\"\\t\")\n",
    "if 'colorcet' in sys.modules:\n",
    "    print(\"colorcet: {0}\".format(cc.__version__), end=\"\\t\")\n",
    "if 'matplotlib' in sys.modules:\n",
    "    print(\"matplotlib: {0}\".format(mpVersion), end=\"\\t\")\n",
    "# if '' in sys.modules:\n",
    "#     print(\": {0}\".format(.__version__), end=\"\\t\")\n",
    "Δt = time() - t0\n",
    "print(f\"\\n\\nΔt: {Δt: 4.1f}s.\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that TensorFlow is finding the GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"tensorflow: {0}\".format(tf.__version__), end=\"\\n\\n\")\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### `getFeatureRepresentations()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureRepresentations(x, layer_names, model):\n",
    "    \"\"\"\n",
    "    Get feature representations of input x for one or more layers in a given model.\n",
    "    Before invoking this, run:\n",
    "\n",
    "       from keras import backend as K\n",
    "\n",
    "    \"\"\"\n",
    "    featMatrices = []\n",
    "    for ln in layer_names:\n",
    "        selectedLayer = model.get_layer(ln)\n",
    "        featRaw = selectedLayer.output\n",
    "        featRawShape = K.shape(featRaw).eval(session=tf_session)\n",
    "        N_l = featRawShape[-1]\n",
    "        M_l = featRawShape[1]*featRawShape[2]\n",
    "        featMatrix = K.reshape(featRaw, (M_l, N_l))\n",
    "        featMatrix = K.transpose(featMatrix)\n",
    "        featMatrices.append(featMatrix)\n",
    "        del selectedLayer\n",
    "        del featRaw\n",
    "        del featRawShape\n",
    "        del N_l\n",
    "        del M_l\n",
    "        del featMatrix\n",
    "    return featMatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getContentLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContentLoss(F, P):\n",
    "    \"\"\"\n",
    "    P represents the content features\n",
    "    \"\"\"\n",
    "    cLoss = 0.5*K.sum(K.square(F - P))\n",
    "    return cLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getGramMatrix()`\n",
    "\n",
    "The Gram matrix is pretty simple:\n",
    "\n",
    "$$\\mathbf{G} = \\mathbf{F} \\cdot \\mathbf{F}^T$$\n",
    "\n",
    "Alternatively, $G_{ij} = F^{ik} F_{kj}$, and this implies that $G_{ij}$ contains the dot product of column $i$ of $\\mathbf{F}$ with row $j$ of $\\mathbf{F}$.\n",
    "Note that $\\mathbf{G}$ is symmetric, and that local information about $\\mathbf{F}$ is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGramMatrix(F):\n",
    "    \"\"\"\n",
    "    F contains the style image feature matrix\n",
    "    \"\"\"\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getStyleLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStyleLoss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_l = K.int_shape(G)[1]\n",
    "        N_l = K.int_shape(G)[0]\n",
    "        G_gram = getGramMatrix(G)\n",
    "        A_gram = getGramMatrix(A)\n",
    "        sLoss += w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_l**2 * M_l**2)\n",
    "        del M_l\n",
    "        del N_l\n",
    "        del G_gram\n",
    "        del A_gram\n",
    "    return sLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getTotalLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTotalLoss(gImPlaceholder, alpha=1.0, beta=10000.0):\n",
    "def getTotalLoss(gImPlaceholder, alpha=1.0, beta=1000.0):\n",
    "    F = getFeatureRepresentations(gImPlaceholder, layer_names=[contentLayerName], model=generatedModel)[0]\n",
    "    Gs = getFeatureRepresentations(gImPlaceholder, layer_names=styleLayerNames, model=generatedModel)\n",
    "    contentLoss = getContentLoss(F, P)\n",
    "    styleLoss = getStyleLoss(ws, Gs, As)\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    del F\n",
    "    del Gs\n",
    "    del contentLoss\n",
    "    del styleLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `calculateLoss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLoss(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate total loss using K.function\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetWidth, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    loss_fcn = K.function([generatedModel.input], [getTotalLoss(generatedModel.input)])\n",
    "    return loss_fcn([gImArr])[0].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `getGrad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGrad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    grad_fcn = K.function([generatedModel.input], \n",
    "                          K.gradients(getTotalLoss(generatedModel.input), [generatedModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    del grad_fcn\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `postProcessArray()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessArray(x):  # , rgbMean):\n",
    "    # Zero-center by mean pixel\n",
    "    if x.shape != (targetWidth, targetHeight, 3):\n",
    "        x = x.reshape((targetWidth, targetHeight, 3))\n",
    "    # I'm guessing that these hard-coded offsets are color-averages for the (train?) set for VGG16 on imagenet\n",
    "    x[..., 0] += 103.939\n",
    "    x[..., 1] += 116.779\n",
    "    x[..., 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[..., ::-1]\n",
    "    x = np.clip(x, 0, 255)\n",
    "    x = x.astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `reprocessArray()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocessArray(x):\n",
    "    x = np.expand_dims(x.astype('float64'), axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `saveOriginalSize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveOriginalSize(x, targetSize, targetImagePath):\n",
    "    xIm = Image.fromarray(x)\n",
    "    xIm = xIm.resize(targetSize)\n",
    "    xIm.save(targetImagePath)\n",
    "    # return xIm\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "\n",
    "### Content image (a photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetWidth = 256\n",
    "targetHeight = 256\n",
    "targetSize = (targetHeight, targetWidth)\n",
    "\n",
    "contentImagePath = './ChildrenKolkataIndiaByLorenJosephOnUnsplash395x256.png'\n",
    "\n",
    "contentImageOrig = Image.open(contentImagePath)\n",
    "contentImageSizeOrig = contentImageOrig.size\n",
    "contentImage = load_img(path=contentImagePath, target_size=targetSize)\n",
    "contentImageArr = img_to_array(contentImage)\n",
    "contentImageArr = K.variable(preprocess_input(np.expand_dims(contentImageArr, axis=0)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style image (Bonnie Wilber painting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleImagePath = './BonnieWilberFamilyFriends395x256.png'\n",
    "\n",
    "styleImage = load_img(path=styleImagePath, target_size=targetSize)\n",
    "styleImageArr = img_to_array(styleImage)\n",
    "styleImageArr = K.variable(preprocess_input(np.expand_dims(styleImageArr, axis=0)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetImage0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "targetImage0 = preprocess_input(np.expand_dims(targetImage0, axis=0))\n",
    "targetImage0Placeholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the image\n",
    "\n",
    "\n",
    "### Create session, instances of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "contentModel = VGG16(include_top=False, weights='imagenet', input_tensor=contentImageArr)\n",
    "styleModel = VGG16(include_top=False, weights='imagenet', input_tensor=styleImageArr)\n",
    "print(\"\\nstyle.Model.summary():\\n\", styleModel.summary())\n",
    "generatedModel = VGG16(include_top=False, weights='imagenet', input_tensor=targetImage0Placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify mutable layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentLayerName = 'block4_conv2'\n",
    "styleLayerNames = [\n",
    "                   'block1_conv1',\n",
    "                   'block2_conv1',\n",
    "                   'block3_conv1',\n",
    "                   'block4_conv1',\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = getFeatureRepresentations(x=contentImageArr, layer_names=[contentLayerName], model=contentModel)[0]\n",
    "As = getFeatureRepresentations(x=styleImageArr, layer_names=styleLayerNames, model=styleModel)\n",
    "ws = np.ones(len(styleLayerNames))/float(len(styleLayerNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the target images\n",
    "\n",
    "#### Show target images at 20 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = np.array(range(2, 22))\n",
    "b = np.exp(np.log(600)/21)\n",
    "b\n",
    "printIterations = [int(b**e) for e in exps]\n",
    "# printIterations.insert(0, 0)\n",
    "print(printIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printIterations = printIterations[13:]\n",
    "# print(printIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set random seeds to enforce consistent results\n",
    "\n",
    "This is described in more detail in Jason Brownlee's [How to Get Reproducible Results with Keras](https://machinelearningmastery.com/reproducible-results-neural-networks-keras/)\n",
    "\n",
    "**Note: this will not necessarily work when running on GPUs.**\n",
    "\n",
    "2 Steps:\n",
    "1. Set `numpy`'s random number generator seed, since Keras itself relies on this\n",
    "1. Set TensorFlow's random number generator seed, as this is invoked by TF's random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(asctime(localtime()))\n",
    "t0 = time()\n",
    "x = targetImage0\n",
    "\n",
    "iterations = 600\n",
    "\n",
    "# Print out initial state of random generated image\n",
    "tlast = t0\n",
    "targetImagePath = f\"./test-395x256at{0:03d}.jpg\"\n",
    "xOut = postProcessArray(x.copy())\n",
    "xIm = saveOriginalSize(xOut, contentImageSizeOrig, targetImagePath)\n",
    "\n",
    "for i in range(1, iterations + 1):\n",
    "    if i > 1:\n",
    "        print(f\"{i:03d}\\t{asctime(localtime())[11:19]}\", end='')\n",
    "    x, minVal, info = fmin_l_bfgs_b(calculateLoss, x.flatten(),\n",
    "                                    fprime=getGrad, maxfun=10, maxiter=3)\n",
    "#                                     fprime=getGrad, maxiter=1)\n",
    "    ti = time()\n",
    "    Δt = ti - tlast\n",
    "    Δti0 = ti - t0\n",
    "    if i == 1:\n",
    "        print(\"\\n  i\\t       t\\t\\t     Δt\\t\\t   Δti0\\t\\t    loss   funcalls     n_iter\\t\\t   image\")\n",
    "        print(f\"{i:03d}\\t{asctime(localtime())[11:19]}\", end='')\n",
    "#     print(int(Δt//3600), int((Δt % 3600)//60), Δt % 60.0, int(Δti0//3600),\n",
    "#           int((Δti0 % 3600)//60), Δti0 % 60.0, minVal,\n",
    "#           info['funcalls'], info['nit'])\n",
    "    print(f\"\\t{int(Δt//3600):2d}h, {int((Δt % 3600)//60):2d}m,\"\n",
    "          f\" {Δt % 60.0:4.1f}s\\t{int(Δti0//3600):2d}h,\"\n",
    "          f\" {int((Δti0 % 3600)//60):2d}m,\"\n",
    "          f\" {Δti0 % 60.0:4.1f}s\\t{minVal:015.2f}\"\n",
    "          f\"\\t{info['funcalls']:3d}\\t{info['nit']:3d}\", end='')\n",
    "    # save current generated image\n",
    "    if i in printIterations:\n",
    "        targetImagePath = f\"./test395x256at{i:03d}.jpg\"\n",
    "        xOut = postProcessArray(x.copy())\n",
    "        saveOriginalSize(xOut, contentImageSizeOrig, targetImagePath)\n",
    "        print(f\"\\t{targetImagePath}\")\n",
    "    else:\n",
    "        print('') \n",
    "    tlast = ti\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "613px",
    "left": "10px",
    "top": "150px",
    "width": "203.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
