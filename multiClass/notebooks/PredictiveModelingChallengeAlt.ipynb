{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling Challenge\n",
    "\n",
    "**Mark Wilber**\n",
    "\n",
    "The challenge here is to build a classifier for 56 FDA food safety violation categories, which are very unbalanced (sizes spanning more than 3 orders of magnitude). There are two components/features:\n",
    "\n",
    "* a boolean, `FDAISCRITICAL`, indicating whether the violation is 'critical' or not\n",
    "* a description of the violation, `VIOCOMMENT`, which can range from 0 to 844 'words'\n",
    "  * (It is shown below, that the two instances with no comments can be safely dropped.)\n",
    "\n",
    "This notebook generates TF-IDF features after extracting unigrams and bigrams, and trains models using logistic regression, random forest, linear SVC and complement Naive Bayes to compare f1 scores and training times.\n",
    "\n",
    "<font color='darkgreen'>**As thise notebook is lengthy, readers will find it much easier to navigate with [Jupyter Nbextensions](https://github.com/ipython-contrib/jupyter_contrib_nbextensions) installed, and Table of Contents (2) selected:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "**Next two lines are useful in the event of external code changes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imports\n",
    "\n",
    "**Next two lines are for pretty output for all prints in a Pandas cell, not just the last.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DataSci` contains generally helpful data science stuff, while `plotHelpers` includes plot functions specifically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/wilber/work/Mlib')\n",
    "from utility import DataSci as util\n",
    "import plotHelpers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time, asctime, gmtime\n",
    "print(asctime(gmtime()))\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# from platform import node\n",
    "import os\n",
    "from os.path import exists\n",
    "# import shutil\n",
    "# from glob import glob\n",
    "from random import random\n",
    "from collections import Counter, OrderedDict\n",
    "import gc\t\t# garbage collection module\n",
    "import pprint\n",
    "# import pickle\n",
    "import timeit\n",
    "\n",
    "print(\"Python version: \", sys.version_info[:])\n",
    "print(\"Un-versioned imports:\\n\")\n",
    "if 'sys' in sys.modules:\n",
    "    print('sys', end=\"\")\n",
    "if 'utility' in sys.modules:\n",
    "    print(', utility', end=\"\")\n",
    "if 'plotHelpers' in sys.modules:\n",
    "    print(', plotHelpers', end=\"\")\n",
    "if 'platform' in sys.modules:\n",
    "    print(', platform', end=\"\")\n",
    "if 'os' in sys.modules:\n",
    "    print(', os', end=\"\")\n",
    "if 'os.path' in sys.modules:\n",
    "    print(', os.path', end=\"\")\n",
    "if 'shutil' in sys.modules:\n",
    "    print(', shutil', end=\"\")\n",
    "if 'glob' in sys.modules:\n",
    "    print(', glob', end=\"\")\n",
    "if 'random' in sys.modules:\n",
    "    print(', random', end=\"\")\n",
    "if 'collections' in sys.modules:\n",
    "    print(', collections', end=\"\")\n",
    "if 'gc' in sys.modules:\n",
    "    print(', gc', end=\"\")\n",
    "if 'pprint' in sys.modules:\n",
    "    print(', pprint', end=\"\")\n",
    "if 'pickle' in sys.modules:\n",
    "    print(', pickle', end=\"\")\n",
    "if 'timeit' in sys.modules:\n",
    "    print(', timeit', end=\"\")\n",
    "\n",
    "duVersion = None\n",
    "from dateutil import __version__ as duVersion\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "\n",
    "scVersion = None\n",
    "from scipy import __version__ as scVersion\n",
    "import scipy.sparse as sp\n",
    "\n",
    "skVersion = None\n",
    "from sklearn import __version__ as skVersion\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "jlVersion = None\n",
    "from joblib import __version__ as jlVersion\n",
    "from joblib import dump, load\n",
    "\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "\n",
    "mpVersion = None\n",
    "from matplotlib import __version__ as mpVersion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\")\n",
    "if 'dateutil' in sys.modules:\n",
    "    print(f\"dateutil: {duVersion}\", end=\"\\t\")\n",
    "if 'numpy' in sys.modules:\n",
    "    print(f\"numpy: {np.__version__}\", end=\"\\t\")\n",
    "if 'pandas' in sys.modules:\n",
    "    print(f\"pandas: {pd.__version__}\", end=\"\\t\")\n",
    "if 'pyreader' in sys.modules:\n",
    "    print(f\"pyreader: {pyreader.__version__}\", end=\"\\t\")\n",
    "if 'scipy' in sys.modules:\n",
    "    print(f\"scipy: {scVersion}\", end=\"\\t\")\n",
    "# if 'tensorflow' in sys.modules:\n",
    "#     print(f\"tensorflow: {tfVersion}\", end=\"\\t\")\n",
    "# if 'keras' in sys.modules:\n",
    "#     print(f\"keras: {kerVersion}\", end=\"\\t\")\n",
    "if 'sklearn' in sys.modules:\n",
    "    print(f\"sklearn: {skVersion}\", end=\"\\t\")\n",
    "if 'joblib' in sys.modules:\n",
    "    print(f\"joblib: {jlVersion}\", end=\"\\t\")\n",
    "if 'seaborn' in sys.modules:\n",
    "    print(f\"seaborn: {sns.__version__}\", end=\"\\t\")\n",
    "if 'colorcet' in sys.modules:\n",
    "    print(f\"colorcet: {cc.__version__}\", end=\"\\t\")\n",
    "if 'matplotlib' in sys.modules:\n",
    "    print(f\"matplotlib: {mpVersion}\", end=\"\\t\")\n",
    "# if '' in sys.modules:\n",
    "#     print(f\": {.__version__}\", end=\"\\t\")\n",
    "Δt = time() - t0\n",
    "print(f\"\\n\\nΔt: {Δt: 4.1f}s.\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle the data\n",
    "\n",
    "### Read data into a DataFrame\n",
    "\n",
    "* Have a very quick look at DataFrame characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"SelectedInspectionReportData.rds\"\n",
    "\n",
    "t0 = time()\n",
    "result = pyreadr.read_r(fname)\n",
    "df = result[None]\n",
    "df.fda_q_fixed = df.fda_q_fixed.astype('int')\n",
    "df.FDAISCRITICAL = df.FDAISCRITICAL.astype('int')\n",
    "Δt = time() - t0\n",
    "print(f\"\\n\\nΔt: {Δt: 4.1f}s.\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(6).T\n",
    "df.tail(6).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns from DataFrame which we won't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['fda_q_fixed', 'VIOCOMMENT', 'FDAISCRITICAL']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis\n",
    "\n",
    "#### Classes and relative balance\n",
    "\n",
    "* The stuff using patches is for placing counts above each rectangle in the bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FDAcodes = list(set(df['fda_q_fixed'].values))\n",
    "print(FDAcodes)\n",
    "classCts = pd.DataFrame(df['fda_q_fixed'].value_counts())\n",
    "with pd.option_context(\"display.max_columns\", 60):\n",
    "    display(classCts.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph.plotValueCounts(df, 'fda_q_fixed', titleText='FDA code frequencies', saveAs='svg', ylim=[0.0, 187500.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The class sizes span nearly 4 orders of magnitude!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "df['commentsWords'] = df['VIOCOMMENT'].apply(lambda s: s.split())\n",
    "t1 = time()\n",
    "Δt = t1 - t0\n",
    "print(f\"Δt: {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(df['commentsWords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of comment lengths\n",
    "\n",
    "* Add length of each comment to DataFrame as `wordFreq` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLens = [len(wordList) for wordList in comments]\n",
    "df['wordFreq'] = wordLens\n",
    "wordFreqMode = df['wordFreq'].mode().values[0]\n",
    "\n",
    "wordCtSorted = sorted(wordLens)\n",
    "print(\"smallest word counts:\\n\", wordCtSorted[:100])\n",
    "print(\"largest word counts:\\n\", wordCtSorted[-101:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(18, 3.5))\n",
    "\n",
    "ph.detailedHistogram(wordLens, ylabel='frequency', volubility=2,\n",
    "                     titleText=f\"Word counts (max: {wordCtSorted[-1]}, mode: {wordFreqMode})\",\n",
    "                     figName=\"WordCountsHist\", ax=ax, ylim = [0.5, 100000.0], ylog=True, saveAs='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(18, 3.5))\n",
    "# ax.hist(wordLens, bins=np.linspace(0, 845, 846))\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_ylim([0.5, 100000.0])\n",
    "# ax.set_ylabel('freqency')\n",
    "# plt.title(f\"Word counts (max: {wordCtSorted[-1]}, mode: {wordFreqMode})\")\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.975])\n",
    "# plt.savefig(\"WordCountsHist.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wordLens\n",
    "del wordCtSorted\n",
    "del df['commentsWords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What FDA codes correspond to those comments having `wordFreq== 0`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['wordFreq']==0]\n",
    "print(\"\\n\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can safely remove a couple of records from the 2nd-most populated category**\n",
    "\n",
    "* Originally there were 1307986 records in `df`, out of which 122314 were in Class 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['wordFreq']!=0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `wordFreq` percentiles\n",
    "\n",
    "* These show that would get 99% coverage of the comments without truncation if were to use, say, 140-element LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe(percentiles=[0.01, 0.05, 0.15, 0.25, 0.5, 0.75, 0.85, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most-common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = [word for wordList in comments for word in wordList]\t\t# Flatten list of lists of words\n",
    "print(len(comments), len(allWords))\n",
    "\n",
    "print(comments[:5], \"\\n\", allWords[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "wordCtr = Counter(allWords)\n",
    "t1 = time()\n",
    "Δt = t1 - t0\n",
    "print(f\"Δt: {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most common words, after removing stop words\n",
    "\n",
    "*Result looks very plausible*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = text.ENGLISH_STOP_WORDS.union(['-'])\n",
    "\n",
    "wcStops = [k for k in wordCtr if k.lower() in stopWords]\n",
    "for k in wcStops:\n",
    "    del wordCtr[k]\n",
    "wordCtr.most_common(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allWords\n",
    "del wordCtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fda_q_fixed` vs. `FDAISCRITICAL`\n",
    "\n",
    "What is the relationship between the critical violation boolean and the FDA code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCrit = df.groupby(['fda_q_fixed', 'FDAISCRITICAL']).count()\n",
    "del dfCrit['VIOCOMMENT']\n",
    "del dfCrit['wordFreq']\n",
    "dfCrit.head(20)\n",
    "\n",
    "dfCrit.reset_index(inplace=True)\n",
    "dfCrit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['xtick.labeltop'] = True\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "dfCrit.plot.scatter('fda_q_fixed', 'FDAISCRITICAL', s=4, c='black', ax=ax)\n",
    "for xv in np.linspace(0.5, 56.5, 57):\n",
    "    _ = plt.axvline(x=xv, c=\"#FFB0FF\", linewidth=1)\n",
    "plt.suptitle('Critical violations vs FDA code')\n",
    "ax.set_xlim([0.5, 56.5])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "plt.savefig('CriticalViolationVsFDAcode.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The critical violations plot shows that `FDAISCRITICAL` should be predictive (and certainly should be included in the model):**\n",
    "\n",
    "* **<font color=\"darkgreen\">classes 30, 32, 34 &amp; 46 *never* have critical violations</font>**\n",
    "* **<font color=\"darkgreen\">classes 7, 26, 27 &amp; 29 *only* have critical violations</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data\n",
    "\n",
    "* Here we use TF-IDF features to represent the comment text.\n",
    "\n",
    "### Split DataFrame by classes\n",
    "\n",
    "* create a `numpy.random.RandomState` instance to keep track of the random number initializer, in order to ensure consistent results throughout\n",
    "\n",
    "`splitDataFrameByClasses()` will create two new DataFrames, dfTr, dfTe, according to the desired splits.\n",
    "\n",
    "<font color='darkgreen'><b>Note that if you just want to do stratified sampling on a numpy array of</b> `X` <b>values,</b> `splitDataFramByClasses()` <b>is not needed.</b> `train_test_split()` <b>accepts the keyword</b> `stratify=myTargetVariable`.</b></font>\n",
    "\n",
    "* Splitting is done on a per-class basis, so that random selection will not, by chance, yield huge imbalances in train-test splits of tiny classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState=0\n",
    "myRandomState = np.random.RandomState(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classColumn = 'fda_q_fixed'\n",
    "dfTr, dfTe = util.splitDataFrameByClasses(df, classColumn,\n",
    "                                          testFrac=0.50,\n",
    "                                          myRandomState=myRandomState)\n",
    "dfTr.shape, dfTe.shape\n",
    "dfTr.head()\n",
    "dfTe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As intended, `splitBalancedDataFrameClasses()` created a new train DataFrame with 10000 $\\times$ 56 = 560000 rows, and a test DataFrame ~ 1307984/2 = 653992 rows.**\n",
    "\n",
    "*The test DataFrame is not exactly an even split of the original, since the splitting is done by class and unioned.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "Let's compute TF-IDFs for each comment using scikit-learn's TF-IDF vectorizer.\n",
    "\n",
    "* We'll use a logarithmic form: `sublinear_df=True`\n",
    "* Ensure Euclidian norms for each vecture: `norm='l2'`\n",
    "* Include bigrams, as well as unigrams: `ngram_range=(1,2)`\n",
    "* English stop words: `stop_words='english'`\n",
    "* toss very infrequent terms (appearing in fewer than 5 comments): `min_df=5`\n",
    "\n",
    "#### Fit TF-IDF  features; transform train set (~40 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTe[['FDAISCRITICAL']].head(16).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2',\n",
    "                        encoding='latin-1', ngram_range=(1, 2),\n",
    "                        stop_words='english')\n",
    "Xtr = tfidf.fit_transform(dfTr.VIOCOMMENT)\n",
    "Xtr.shape\n",
    "yTr = dfTr.fda_q_fixed\n",
    "t1 = time()\n",
    "Δt = t1 - t0\n",
    "print(f\"Δt: {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xtr has 653979 ~ 653992 = 1307984 / 2 rows and ~196k columns. The latter represent the ~196k features in the training set unigram and bigram 'vocabulary'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xtr)\n",
    "for i, row in enumerate(Xtr):\n",
    "    if i > 1:\n",
    "        break\n",
    "    print(i, \"\\n\", row)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform test set (~35 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "Xte = tfidf.transform(dfTe.VIOCOMMENT)\n",
    "Xte.shape\n",
    "yTe = dfTe.fda_q_fixed\n",
    "t1 = time()\n",
    "Δt = t1 - t0\n",
    "print(f\"Δt: {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**same number of columns for Xte, as for Xtr.**\n",
    "\n",
    "#### Sanity check: show features most correlated with classes\n",
    "\n",
    "* Figure out which of 196k features are most correlated with each of the FDA codes (~1 minute, 10 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "N = 5\n",
    "\n",
    "FDAcodes = sorted(list(set(df.fda_q_fixed)))\n",
    "\n",
    "for FDAcode in FDAcodes:\n",
    "    Xχ2 = chi2(Xtr, yTr==FDAcode)\n",
    "    indices = np.argsort(Xχ2[0])\n",
    "    featureNames = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in featureNames if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in featureNames if len(v.split(' ')) == 2]\n",
    "    print(f\"\\nFCA code {FDAcode:02d}:\")\n",
    "    print(\"Most correlated unigrams::\\t{{{}\".format('}  {'.join(unigrams[-N:])), end='}')\n",
    "    print(\"\\nMost correlated bigrams::\\t{{{}\".format('}  {'.join(bigrams[-N:])), end='}')\n",
    "t1 = time()\n",
    "Δt = t1 - t0\n",
    "print(f\"\\n\\nΔt: {int(Δt//60)}m, {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add `FDAISCRITICAL` column vales to `Xtr` and `Xte`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrp = sp.hstack([Xtr, sp.csr_matrix(dfTr[['FDAISCRITICAL']])], 'csr')\n",
    "np.shape(Xtrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtep = sp.hstack([Xte, sp.csr_matrix(dfTe[['FDAISCRITICAL']])], 'csr')\n",
    "np.shape(Xtep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Xtr\n",
    "del Xte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some garbage collection before building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print('\\nCollecting {} ...'.format(i))\n",
    "    n = gc.collect()\n",
    "    print('Unreachable objects:', n)\n",
    "    print('Remaining Garbage:', end=' ')\n",
    "    pprint.pprint(gc.garbage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "#### TF-IDF with `FDAISCRITICAL`\n",
    "\n",
    "* Run defaults for now, except `class_weight='balanced'`\n",
    "* `n_jobs=7` means use 8 processors (as it is set to $n_{\\mathrm{threads}} - 1$)\n",
    "* For np.shape(Xtrp) = (560000, 196227), fit takes ~30 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(Xtrp), np.shape(yTr), np.shape(Xtep), np.shape(yTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "LRname = 'LogisticRegressor0.joblib'\n",
    "\n",
    "if os.path.isfile(LRname):\n",
    "    LR = load(LRname)\n",
    "    t1 = time()\n",
    "else:\n",
    "    CV = 5\n",
    "    LR = LogisticRegression(random_state=myRandomState, n_jobs=7,\n",
    "                            solver='newton-cg', class_weight='balanced')\n",
    "    t0 = time()\n",
    "    LR.fit(Xtrp, yTr)\n",
    "    t1 = time()\n",
    "    Δt01 = t1 - t0\n",
    "    print(\"Δt01: {0} m, {1:4.1f} s.\".format(int(Δt01//60), Δt01 % 60.0))\n",
    "\n",
    "yPred = LR.predict(Xtep)\n",
    "t2 = time()\n",
    "Δt12 = t2 - t1\n",
    "print(\"Δt12: {0} m, {1:4.1f} s.\".format(int(Δt12//60), Δt12 % 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(yTe[:20].values)\n",
    "print(yPred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model to disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(LRname):\n",
    "    dump(LR, LRname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMat = confusion_matrix(yTe, yPred)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.trace(confusionMat)/np.sum(confusionMat)\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis=1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis=0)\n",
    "print(f\"accuracy: {accuracy:0.3f}, \"\n",
    "      f\"<precision>: {np.mean(precision):0.3f}, \"\n",
    "      f\"<recall>: {np.mean(recall):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall, precision by class\n",
    "\n",
    "Note:\n",
    "\n",
    "* `macro avg`: $\\frac{1}{K}\\sum_k m_k$, where $K$ is count of classes and $m_k$ is a given metric for class $k$\n",
    "* `weighted avg`: $\\frac{1}{N}\\sum_k n_k \\cdot m_k$, where $N$ is count of data instance, $n_k$ is the count of points in class $k$ and $m_k$ is a given metric for class $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(yTe.values, yPred, target_names=[str(c)for c in FDAcodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCts = dfTe['fda_q_fixed'].value_counts()\n",
    "\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis = 1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis = 0)\n",
    "f1 = 2.0*precision*recall/(precision + recall)\n",
    "print(\"class\\tprecision\\trecall\\tf1\\tsize\")\n",
    "\n",
    "for FDAcode, classCt in classCts.iteritems():\n",
    "    print(f\"{FDAcode}\\t{precision[FDAcode - 1]:0.3f}\\t\\t{recall[FDAcode - 1]:0.3f}\\t{f1[FDAcode - 1]:0.3f}\\t\\t{classCt:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot confusion matrix\n",
    "\n",
    "* As this is a straight confusion matrix, diagonal elements mostly reflect class size in test set\n",
    "* *This is hard to interpret by visual inspection alone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFontSz = 16\n",
    "tickFontSz = 13\n",
    "titleFontSz = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes,\n",
    "                       ylabels=FDAcodes, titleText = 'Logistic Regression',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot recall confusion matrix (normalized by row)\n",
    "\n",
    "* diagonal elements now represent the *recall* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='recall',\n",
    "                       ylabels=FDAcodes, titleText = 'Logistic Regression',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot precision confusion matrix (normalized by column)\n",
    "\n",
    "* diagonal elements now represent the *precision* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='precision',\n",
    "                       ylabels=FDAcodes, titleText = 'Logistic Regression',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some garbage collection before building RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print('\\nCollecting {} ...'.format(i))\n",
    "    n = gc.collect()\n",
    "    print('Unreachable objects:', n)\n",
    "    print('Remaining Garbage:', end=' ')\n",
    "    pprint.pprint(gc.garbage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "#### TF-IDF with `FDAISCRITICAL`, `max_depth=250`\n",
    "\n",
    "* Run defaults for now, except `n_estimators=160` (default is 10)\n",
    "* For np.shape(Xtr) = (560000, 178558), fit takes ~150 min.\n",
    "\n",
    "<font color='darkred'>***The very long training time in this instance is due to memory swapping.\n",
    "(Fortunately, on my 12 GB machine, the swap space is on a flash drive.)\n",
    "Reducing the `max_depth` from 250 should help to reduce the memory requirements.***</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.shape(Xtrp), np.shape(yTr), np.shape(Xtep), np.shape(yTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "RFname = 'RandomForest0.joblib'\n",
    "\n",
    "if os.path.isfile(RFname):\n",
    "    RF = load(RFname)\n",
    "    t1 = time()\n",
    "else:\n",
    "    RF = RandomForestClassifier(random_state=myRandomState, n_jobs=7, n_estimators=160,\n",
    "                                max_depth=250, class_weight='balanced')\n",
    "    t0 = time()\n",
    "    RF.fit(Xtrp, yTr)\n",
    "    t1 = time()\n",
    "    Δt01 = t1 - t0\n",
    "    print(\"Δt01: {0} m, {1:4.1f} s.\".format(int(Δt01//60), Δt01 % 60.0))\n",
    "\n",
    "yPred = RF.predict(Xtep)\n",
    "t2 = time()\n",
    "Δt12 = t2 - t1\n",
    "print(\"Δt12: {0} m, {1:4.1f} s.\".format(int(Δt12//60), Δt12 % 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(yTe[:20].values)\n",
    "print(yPred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model to disk**\n",
    "\n",
    "<font color=\"darkred\">Nope. Not agonna do this; model is yuge &mdash; 15 GB!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isfile(RFname):\n",
    "#     dump(RF, RFname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMat = confusion_matrix(yTe, yPred)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.trace(confusionMat)/np.sum(confusionMat)\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis=1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis=0)\n",
    "print(f\"accuracy: {accuracy:0.3f}, \"\n",
    "      f\"<precision>: {np.mean(precision):0.3f}, \"\n",
    "      f\"<recall>: {np.mean(recall):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall, precision by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(yTe.values, yPred, target_names=[str(c)for c in FDAcodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCts = dfTe['fda_q_fixed'].value_counts()\n",
    "\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis = 1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis = 0)\n",
    "f1 = 2.0*precision*recall/(precision + recall)\n",
    "print(\"class\\tprecision\\trecall\\tf1\\tsize\")\n",
    "\n",
    "for FDAcode, classCt in classCts.iteritems():\n",
    "    print(f\"{FDAcode}\\t{precision[FDAcode - 1]:0.3f}\\t\\t{recall[FDAcode - 1]:0.3f}\\t{f1[FDAcode - 1]:0.3f}\\t\\t{classCt:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot confusion matrix\n",
    "\n",
    "* As this is a straight confusion matrix, diagonal elements mostly reflect class size in test set\n",
    "* *This is hard to interpret by visual inspection alone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFontSz = 16\n",
    "tickFontSz = 13\n",
    "titleFontSz = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes,\n",
    "                       ylabels=FDAcodes, titleText = 'Random Forest (160 estimators, max depth=250)',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot recall confusion matrix (normalized by row)\n",
    "\n",
    "* diagonal elements now represent the *recall* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='recall',\n",
    "                       ylabels=FDAcodes, titleText = 'Random Forest (160 estimators, max depth=250)',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot precision confusion matrix (normalized by column)\n",
    "\n",
    "* diagonal elements now represent the *precision* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='precision',\n",
    "                       ylabels=FDAcodes, titleText = 'Random Forest (160 estimators, max depth=250)',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some garbage collection before building RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print('\\nCollecting {} ...'.format(i))\n",
    "    n = gc.collect()\n",
    "    print('Unreachable objects:', n)\n",
    "    print('Remaining Garbage:', end=' ')\n",
    "    pprint.pprint(gc.garbage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC\n",
    "\n",
    "#### TF-IDF with `FDAISCRITICAL`\n",
    "\n",
    "* `penalty='l1', dual=False, class_weight='balanced', random_state=myRandomState\n",
    "* For np.shape(Xtr) = (560000, 178558), fit takes ~45 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.shape(Xtrp), np.shape(yTr), np.shape(Xtep), np.shape(yTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "LSVCname = 'LinearSVC0.joblib'\n",
    "\n",
    "if os.path.isfile(LSVCname):\n",
    "    RF = load(RFname)\n",
    "    t1 = time()\n",
    "else:\n",
    "    LSVC = LinearSVC(random_state=myRandomState, penalty='l1',\n",
    "                     dual=False, class_weight='balanced')\n",
    "    t0 = time()\n",
    "    LSVC.fit(Xtrp, yTr)\n",
    "    t1 = time()\n",
    "    Δt01 = t1 - t0\n",
    "    print(\"Δt01: {0} m, {1:4.1f} s.\".format(int(Δt01//60), Δt01 % 60.0))\n",
    "\n",
    "yPred = LSVC.predict(Xtep)\n",
    "t2 = time()\n",
    "Δt = t2 - t1\n",
    "print(f\"\\n\\nΔt: {int(Δt//60)}m, {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(yTe[:20].values)\n",
    "print(yPred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model to disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(LSVCname):\n",
    "    dump(LSVC, LSVCname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMat = confusion_matrix(yTe, yPred)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.trace(confusionMat)/np.sum(confusionMat)\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis=1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis=0)\n",
    "print(f\"accuracy: {accuracy:0.3f}, \"\n",
    "      f\"<precision>: {np.mean(precision):0.3f}, \"\n",
    "      f\"<recall>: {np.mean(recall):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall, precision by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(yTe.values, yPred, target_names=[str(c)for c in FDAcodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCts = dfTe['fda_q_fixed'].value_counts()\n",
    "\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis = 1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis = 0)\n",
    "f1 = 2.0*precision*recall/(precision + recall)\n",
    "print(\"class\\tprecision\\trecall\\tf1\\tsize\")\n",
    "\n",
    "for FDAcode, classCt in classCts.iteritems():\n",
    "    print(f\"{FDAcode}\\t{precision[FDAcode - 1]:0.3f}\\t\\t{recall[FDAcode - 1]:0.3f}\\t{f1[FDAcode - 1]:0.3f}\\t\\t{classCt:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot confusion matrix\n",
    "\n",
    "* As this is a straight confusion matrix, diagonal elements mostly reflect class size in test set\n",
    "* *This is hard to interpret by visual inspection alone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFontSz = 16\n",
    "tickFontSz = 13\n",
    "titleFontSz = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes,\n",
    "                       ylabels=FDAcodes, titleText = \"Linear SVC ('l1' penalty, dual=False)\",\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot recall confusion matrix (normalized by row)\n",
    "\n",
    "* diagonal elements now represent the *recall* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='recall',\n",
    "                       ylabels=FDAcodes, titleText = \"Linear SVC ('l1' penalty, dual=False)\",\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot precision confusion matrix (normalized by column)\n",
    "\n",
    "* diagonal elements now represent the *precision* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='precision',\n",
    "                       ylabels=FDAcodes, titleText = \"Linear SVC ('l1' penalty, dual=False)\",\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del LSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some garbage collection before building RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print('\\nCollecting {} ...'.format(i))\n",
    "    n = gc.collect()\n",
    "    print('Unreachable objects:', n)\n",
    "    print('Remaining Garbage:', end=' ')\n",
    "    pprint.pprint(gc.garbage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes\n",
    "\n",
    "#### TF-IDF with `FDAISCRITICAL`\n",
    "\n",
    "* default hyperparameters, except `fit_prior=False`, as we have enforced train clasess with ≥ 14 elements\n",
    "* For np.shape(Xtr) = (560000, 178558), fit takes ~ min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.shape(Xtrp), np.shape(yTr), np.shape(Xtep), np.shape(yTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(asctime(gmtime()))\n",
    "CNBname = 'ComplementNaiveBayes0.joblib'\n",
    "\n",
    "if os.path.isfile(CNBname):\n",
    "    CNB = load(CNBname)\n",
    "    t1 = time()\n",
    "else:\n",
    "    CNB = ComplementNB(fit_prior=False)\n",
    "    t0 = time()\n",
    "    CNB.fit(Xtrp, yTr)\n",
    "    t1 = time()\n",
    "    Δt01 = t1 - t0\n",
    "    print(\"Δt01: {0} m, {1:4.1f} s.\".format(int(Δt01//60), Δt01 % 60.0))\n",
    "\n",
    "yPred = CNB.predict(Xtep)\n",
    "t2 = time()\n",
    "Δt = t2 - t1\n",
    "print(f\"\\n\\nΔt: {int(Δt//60)}m, {Δt % 60.0:4.1f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(yTe[:20].values)\n",
    "print(yPred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model to disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(CNBname):\n",
    "    dump(CNB, CNBname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMat = confusion_matrix(yTe, yPred)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.trace(confusionMat)/np.sum(confusionMat)\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis=1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis=0)\n",
    "print(f\"accuracy: {accuracy:0.3f}, \"\n",
    "      f\"<precision>: {np.mean(precision):0.3f}, \"\n",
    "      f\"<recall>: {np.mean(recall):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall, precision by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(yTe.values, yPred, target_names=[str(c)for c in FDAcodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCts = dfTe['fda_q_fixed'].value_counts()\n",
    "\n",
    "recall = np.diag(confusionMat)/np.sum(confusionMat, axis = 1)\n",
    "precision = np.diag(confusionMat)/np.sum(confusionMat, axis = 0)\n",
    "f1 = 2.0*precision*recall/(precision + recall)\n",
    "print(\"class\\tprecision\\trecall\\tf1\\tsize\")\n",
    "\n",
    "for FDAcode, classCt in classCts.iteritems():\n",
    "    print(f\"{FDAcode}\\t{precision[FDAcode - 1]:0.3f}\\t\\t{recall[FDAcode - 1]:0.3f}\\t{f1[FDAcode - 1]:0.3f}\\t\\t{classCt:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot confusion matrix\n",
    "\n",
    "* As this is a straight confusion matrix, diagonal elements mostly reflect class size in test set\n",
    "* *This is hard to interpret by visual inspection alone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFontSz = 16\n",
    "tickFontSz = 13\n",
    "titleFontSz = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes,\n",
    "                       ylabels=FDAcodes, titleText = 'Complement Naive Bayes',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot recall confusion matrix (normalized by row)\n",
    "\n",
    "* diagonal elements now represent the *recall* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='recall',\n",
    "                       ylabels=FDAcodes, titleText = 'Complement Naive Bayes',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot precision confusion matrix (normalized by column)\n",
    "\n",
    "* diagonal elements now represent the *precision* for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "ph.plotConfusionMatrix(confusionMat, saveAs='pdf', xlabels=FDAcodes, type='precision',\n",
    "                       ylabels=FDAcodes, titleText = 'Complement Naive Bayes',\n",
    "                       ax = ax,  xlabelFontSz=labelFontSz,\n",
    "                       ylabelFontSz=labelFontSz, xtickFontSz=tickFontSz,\n",
    "                       ytickFontSz=tickFontSz, titleFontSz=titleFontSz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
